{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Results Processing\n",
    "\n",
    "This notebook processes raw results from the `raw/` directory and formats them into comparable JSON files for analysis.\n",
    "\n",
    "## Task Description\n",
    "\n",
    "The main task is to transform raw results into standardized comparison-ready formats:\n",
    "\n",
    "1. **Input**: Raw JSON files from the `raw/` directory containing model predictions\n",
    "2. **Output**: Formatted JSON files where:\n",
    "   - **Key**: Patient ID\n",
    "   - **Value**: List of complications\n",
    "   - **For strict results**: Value is a list of complications concatenated with their grading using underscore (`_`) separator\n",
    "\n",
    "## Processing Steps\n",
    "\n",
    "1. Parse raw JSON files containing model outputs\n",
    "2. Extract patient IDs and corresponding complications\n",
    "3. Format complications according to the target schema\n",
    "4. Generate comparison-ready JSON files for downstream analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def process_comprehensive_results(file, center=\"center1\"):\n",
    "    \"\"\"\n",
    "    Process comprehensive results from raw JSON files and format them for comparison.\n",
    "    \n",
    "    Args:\n",
    "        file (str): Path to the raw JSON file to process\n",
    "        center (str): Output directory name (default: \"center1\")\n",
    "    \n",
    "    The function extracts complications data from various JSON formats and \n",
    "    standardizes them into a consistent structure for downstream analysis.\n",
    "    \"\"\"\n",
    "    # Load the raw JSON data\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Process each patient record\n",
    "    for k, v in data.items():\n",
    "        # Extract the content field which contains the complications data\n",
    "        tmp = v[\"content\"]\n",
    "        \n",
    "        # Handle different content formats:\n",
    "        if isinstance(tmp, dict):\n",
    "            # Direct dictionary format - extract complications directly\n",
    "            tmp = tmp[\"complications\"]\n",
    "        elif isinstance(tmp, str) and \"```json\" in tmp:\n",
    "            # Markdown-wrapped JSON format - extract and parse the JSON block\n",
    "            tmp = tmp.split(\"```json\")[1].split(\"```\")[0]\n",
    "            tmp = json.loads(tmp)[\"complications\"]\n",
    "        else:\n",
    "            # String JSON format - parse directly and extract complications\n",
    "            tmp = json.loads(tmp)[\"complications\"]\n",
    "        complies = [t[\"name\"] for t in tmp]\n",
    "        # Remove parentheses and their contents (including both half-width and full-width parentheses)\n",
    "        for i in range(len(complies)):\n",
    "            # Remove half-width parentheses and their contents\n",
    "            complies[i] = re.sub(r'\\([^)]*\\)', '', complies[i])\n",
    "            # Remove full-width parentheses and their contents\n",
    "            complies[i] = re.sub(r'（[^）]*）', '', complies[i])\n",
    "            # Remove any remaining whitespace\n",
    "            complies[i] = complies[i].strip()\n",
    "        data[k] = complies\n",
    "    \n",
    "    # Save the processed data to the output directory\n",
    "    with open(f\"{center}/{Path(file).name}\", 'w') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Processed {file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed raw/claude3_7_comprehensive.json\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "process_comprehensive_results(\"raw/claude3_7_comprehensive.json\", \"center1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_json_text(text):\n",
    "    # Find all ```json and ``` markers\n",
    "    start_markers = [m.start() for m in re.finditer(r'```json', text)]\n",
    "    end_markers = [m.start() for m in re.finditer(r'```', text) if not text[max(0, m.start()-4):m.start()].endswith('json')]\n",
    "    \n",
    "    # If multiple json code blocks are found, raise an error\n",
    "    if len(start_markers) > 1:\n",
    "        raise ValueError(\"Multiple ```json markers found, cannot determine which one to use\")\n",
    "    \n",
    "    # If ```json marker is found\n",
    "    if start_markers:\n",
    "        start_idx = start_markers[0] + 7  # Length of ```json is 7\n",
    "        \n",
    "        # Find the corresponding end marker\n",
    "        valid_end_markers = [idx for idx in end_markers if idx > start_idx]\n",
    "        if not valid_end_markers:\n",
    "            raise ValueError(\"Cannot find matching end marker ```\")\n",
    "        \n",
    "        end_idx = valid_end_markers[0]\n",
    "        \n",
    "        # Extract content between ```json and ```\n",
    "        text = text[start_idx:end_idx].strip()\n",
    "        return text\n",
    "    \n",
    "    # If no ```json marker is found, return original text\n",
    "    else:\n",
    "        first_brace = text.find('{')\n",
    "        last_brace = text.rfind('}')\n",
    "        \n",
    "        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:\n",
    "            text = text[first_brace:last_brace+1].strip()\n",
    "            return text\n",
    "        return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rules for processing complications list\n",
    "# Rule 1: If all evaluations yield negative results, output \"no postoperative complications\"\n",
    "# Rule 2: Identification of specific infectious complications automatically excludes diagnosis of \"infection of unknown source\" to prevent redundancy\n",
    "def rules(list):\n",
    "    # Rule 1: Return \"no postoperative complications\" for empty list\n",
    "    if len(list) == 0:\n",
    "        return [\"无术后并发症\"]\n",
    "    # Rule 2: Handle mutual exclusivity between \"unknown source\" infection and specific infections\n",
    "    else:\n",
    "        has_unknown_source = any(\"来源不明\" in item for item in list)\n",
    "        if has_unknown_source:\n",
    "            # Check for other specific infection-related complications\n",
    "            has_other_infection = any(\"感染\" in item and \"来源不明\" not in item for item in list)\n",
    "            has_pneumonia = any(\"肺炎\" in item for item in list)\n",
    "            \n",
    "            # If specific infection types exist, remove \"unknown source\" to ensure clinically coherent and mutually exclusive diagnostic conclusions\n",
    "            if has_other_infection or has_pneumonia:\n",
    "                list = [item for item in list if \"来源不明\" not in item]\n",
    "        return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Open modular JSON file based on column name\n",
    "import json\n",
    "def process_targeted_results(path, center=\"center1\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        tmp_dict = json.load(f)\n",
    "    final_dict = {}\n",
    "    for key, value in tmp_dict.items():\n",
    "        result_list = []\n",
    "        for k, v in value.items():\n",
    "            try:\n",
    "                result = v[\"content\"]\n",
    "                result_dict = json.loads(clean_json_text(result))\n",
    "                if result_dict[\"bool\"] == \"True\" or result_dict[\"bool\"] == True:\n",
    "                    result_list.append(k)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {path}: {v} - {e}\")\n",
    "                pass\n",
    "        final_dict[key] = rules(result_list)\n",
    "    with open(f\"{center}/{Path(path).name}\", 'w') as f:\n",
    "        json.dump(final_dict, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Processed {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw/deepseek_r1_targeted.json\n",
      "Processed raw/deepseek_r1_targeted.json\n"
     ]
    }
   ],
   "source": [
    "# an example\n",
    "process_targeted_results(\"raw/deepseek_r1_targeted.json\", \"center1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strict results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import demjson3\n",
    "def extract_complications_with_grading_from_comprehensive(data):\n",
    "    \"\"\"\n",
    "    Extract complications from o1_hard_prompte for each case\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing case ID and corresponding complications, each complication is in \"name_grading\" format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract complications\n",
    "    result = {}\n",
    "    for case_id, case_data in data.items():\n",
    "        # Parse JSON in content field\n",
    "        try:\n",
    "            # If case_data doesn't have 'content' key, use itself\n",
    "            if 'content' in case_data:\n",
    "                content = case_data['content']\n",
    "            else:\n",
    "                content = case_data\n",
    "            # Check if there's ```json marker\n",
    "            if \"```json\" in content:\n",
    "                # Extract content between ```json and ```\n",
    "                json_content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                content = demjson3.decode(json_content)\n",
    "            else:\n",
    "                try:\n",
    "                    content = demjson3.decode(content)\n",
    "                except:\n",
    "                    pass\n",
    "            # Extract complications and convert to name_grading format\n",
    "            if 'complications' in content:\n",
    "                complications_list = []\n",
    "                for comp in content['complications']:\n",
    "                    if isinstance(comp, dict) and 'name' in comp:\n",
    "                        # Remove parentheses and content within them\n",
    "                        name = re.sub(r'[\\(（][^)）]*[\\)）]', '', comp['name']).strip()\n",
    "                        # If name contains \"其他\" (other), discard this complication\n",
    "                        if \"其他\" not in name:\n",
    "                            grading = comp.get('grading', 'Null')\n",
    "                            complications_list.append(f\"{name}_{grading}\")\n",
    "                result[case_id] = complications_list\n",
    "        except json.JSONDecodeError:\n",
    "            # print(content)\n",
    "            # Handle JSON parsing errors\n",
    "            result[case_id] = [\"Error: Cannot parse JSON content\"]\n",
    "        except Exception as e:\n",
    "            # Handle other errors\n",
    "            result[case_id] = [f\"Error: {str(e)}\"]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_complications_with_grading_from_targeted(data):\n",
    "    \"\"\"\n",
    "    Extract complications and their grading from divided data\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary containing divided data\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing case ID and corresponding complications, each complication is in \"name_grading\" format\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define rules\n",
    "    def rules(complications_list):\n",
    "        if len(complications_list) == 0:\n",
    "            return [\"无术后并发症_Null\"]\n",
    "        else:\n",
    "            # Check if contains \"来源不明\" (unknown source)\n",
    "            has_unknown_source = any(\"来源不明\" in item[\"name\"] for item in complications_list)\n",
    "            if has_unknown_source:\n",
    "                # Check if there are other infection-related elements\n",
    "                has_other_infection = any(\"感染\" in item[\"name\"] and \"来源不明\" not in item[\"name\"] for item in complications_list)\n",
    "                has_pneumonia = any(\"肺炎\" in item[\"name\"] for item in complications_list)\n",
    "                \n",
    "                # If there are other infection-related elements, remove \"来源不明\"\n",
    "                if has_other_infection or has_pneumonia:\n",
    "                    complications_list = [item for item in complications_list if \"来源不明\" not in item[\"name\"]]\n",
    "            \n",
    "            # Convert to name_grading format\n",
    "            return [f\"{item['name']}_{item['grading']}\" for item in complications_list]\n",
    "    \n",
    "    # Extract complications and grading\n",
    "    result = {}\n",
    "    for case_id, case_data in data.items():\n",
    "        try:\n",
    "            complications_list = []\n",
    "            # Iterate through each complication\n",
    "            for complication_name, complication_data in case_data.items():\n",
    "                try:\n",
    "                    # If complication_data doesn't have 'content' key, use itself\n",
    "                    if 'content' in complication_data:\n",
    "                        content = complication_data['content']\n",
    "                    else:\n",
    "                        content = complication_data\n",
    "                    \n",
    "                    # Check if there's ```json marker\n",
    "                    if \"```json\" in content:\n",
    "                        # Extract content between ```json and ```\n",
    "                        json_content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                        content_json = demjson3.decode(json_content)\n",
    "                    else:\n",
    "                        try:\n",
    "                            content_json = demjson3.decode(content)\n",
    "                        except:\n",
    "                            content_json = content\n",
    "                    \n",
    "                    if isinstance(content_json, dict) and 'bool' in content_json and content_json['bool'] == True:\n",
    "                        # If bool is True, add to complications list\n",
    "                        grading = content_json.get('grading', 'Null')\n",
    "                        # Remove parentheses and content within them\n",
    "                        name = re.sub(r'[\\(（][^)）]*[\\)）]', '', complication_name).strip()\n",
    "                        # If name contains \"其他\" (other), discard this complication\n",
    "                        if \"其他\" not in name:\n",
    "                            complications_list.append({\n",
    "                                \"name\": name,\n",
    "                                \"grading\": grading\n",
    "                            })\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"JSON parsing error: {case_id} - {complication_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error {case_id} - {complication_name}: {str(e)}\")\n",
    "            \n",
    "            # Apply rules to process complications list and convert to name_grading format\n",
    "            result[case_id] = rules(complications_list)\n",
    "        except Exception as e:\n",
    "            # Handle other errors\n",
    "            result[case_id] = [f\"Error: {str(e)}_Null\"]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_human_gold_strict_data(center, file_type):\n",
    "    \"\"\"\n",
    "    Process comprehensive data (human or gold) for a given center\n",
    "    \n",
    "    Args:\n",
    "        center: str, center name (e.g., 'center1', 'center2')\n",
    "        file_type: str, file type ('human' or 'gold')\n",
    "    \"\"\"\n",
    "    # Read data from source\n",
    "    with open(f'../data_source/{center}/{file_type}.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract complications data\n",
    "    complications_data = extract_complications_with_grading_from_comprehensive(data)\n",
    "    \n",
    "    # Write to output file\n",
    "    with open(f'strict/{center}/{file_type}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(complications_data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process human data using the function\n",
    "process_human_gold_strict_data('center1', 'human_expert')  # Only example data with one case for privacy reasons\n",
    "process_human_gold_strict_data('center2', 'human_expert')  # Not publicly available for privacy reasons\n",
    "\n",
    "# Process gold data using the function\n",
    "process_human_gold_strict_data('center1', 'gold_standard')  # Only example data with one case for privacy reasons\n",
    "process_human_gold_strict_data('center2', 'gold_standard')  # Not publicly available for privacy reasons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_to_strict_data(center, file):\n",
    "    \"\"\"\n",
    "    Process comprehensive data (human or gold) for a given center\n",
    "    \n",
    "    Args:\n",
    "        center: str, center name (e.g., 'center1', 'center2')\n",
    "        file: str, files in raw folder\n",
    "    \"\"\"\n",
    "    # Read data from source\n",
    "    with open(f'raw/{center}/{file}.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract complications data\n",
    "    if \"comprehensive\" in file:\n",
    "        complications_data = extract_complications_with_grading_from_comprehensive(data)\n",
    "    elif \"targeted\" in file:\n",
    "        complications_data = extract_complications_with_grading_from_targeted(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid file: {file}\")\n",
    "    \n",
    "    # Write to output file\n",
    "    with open(f'strict/{center}/{file}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(complications_data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "process_raw_to_strict_data(\"center1\", \"deepseek_r1_targeted.json\")\n",
    "process_raw_to_strict_data(\"center1\", \"o1_comprehensive.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
