{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No think label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nothink_comprehensive_prompt(text):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive prompt for multi-complication assessment, specifically designed *without* a Chain of Thought (CoT) requirement.\n",
    "\n",
    "    This function creates a \"comprehensive strategy\" prompt that instructs the AI to evaluate all possible\n",
    "    post-operative complications simultaneously. Unlike CoT-based prompts, it does not require the AI to\n",
    "    provide explicit step-by-step reasoning. It directly formats patient medical records and demands\n",
    "    structured JSON output for diagnosis.\n",
    "\n",
    "    Key features of this comprehensive strategy prompt (without CoT):\n",
    "    - Comprehensive evaluation of all 22 predefined complications at once.\n",
    "    - No mandatory \"think\" field, allowing for direct diagnosis without explicit step-by-step reasoning.\n",
    "    - Structured JSON output with diagnosis components.\n",
    "    - Direct formatting of medical records into the prompt.\n",
    "\n",
    "    Args:\n",
    "        text (str): The full content of the prompt definition file (e.g., prompt.md),\n",
    "                    containing the definitions of post-operative complication categories\n",
    "                    and their grading rules.\n",
    "\n",
    "    Returns:\n",
    "        str: A complete prompt string ready for use with medical record content appended.\n",
    "             The prompt includes instructions, complication definitions, and the required output format.\n",
    "    \"\"\"\n",
    "    # Define markers to identify and extract specific sections from the input text.\n",
    "    complication_flag = \"## 术后并发症类别\"\n",
    "    grading_flag = \"## 常规分级\"\n",
    "\n",
    "    # Extract the section detailing complication categories and their definitions.\n",
    "    complications = text[text.find(complication_flag) + len(complication_flag): text.find(grading_flag)]\n",
    "    # Extract the section defining general grading rules and format it for inclusion in the prompt.\n",
    "    grading = text[text.find(grading_flag) + len(grading_flag):].replace(\"\\n\", \"\\t\")\n",
    "\n",
    "    # Define the initial instruction for the AI model, setting its role and task.\n",
    "    instruction = '你是一名资深外科医生，你的任务是根据患者的资料，判断患者术后出现哪些并发症，并发症的诊断依据:\\n'                \n",
    "    \n",
    "    # Define the desired output structure in JSON format, including specific instructions\n",
    "    # on naming, grading, and handling cases with no complications.\n",
    "    output_structure = f\"\"\"\n",
    "### 输出json格式\n",
    "输出一个列表，每个元素为一个字典，包含：\n",
    "    * name: 并发症的名称，必须是22个预定义并发症之一\n",
    "    * grading: 严重程度分级，只能是以下四个选项之一：\n",
    "        * \"轻\" - 轻度：无需治疗\n",
    "        * \"中\" - 中度：需治疗，无长期影响\n",
    "        * \"重\" - 重度：导致器官功能受损或死亡，显著延长住院时间\n",
    "        * \"Null\" - 无分级\n",
    "\n",
    "完整格式示例：\n",
    "[\n",
    "    {{\n",
    "      \"name\": \"非心脏手术后心肌损伤\",\n",
    "      \"grading\": \"Null\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "注意：\n",
    "- 如果没有发现术后并发症，请在数组中写明\"无术后并发症\"，分级为“Null”。\n",
    "- 请列举你认为的所有并发症，但必须包含在上述的22个之中，禁止输出自定义的并发症\n",
    "- 常规分级按照{grading}\n",
    "### 病历资料\n",
    "\"\"\"\n",
    "    # Concatenate the instruction, extracted complication categories, and output structure\n",
    "    # to form the complete prompt string.\n",
    "    return instruction + complications + output_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "import json\n",
    "prompts_output_path = \"comprehensive_prompts_nothink.json\"\n",
    "\n",
    "with open(\"defination.md\", \"r\") as f:\n",
    "    text = f.read()\n",
    "comprehensive_prompts = {}\n",
    "with open(\"../data_source/medical_record_example.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for id, medical_record in data.items():\n",
    "    comprehensive_prompts[id] = get_nothink_comprehensive_prompt(text) + medical_record\n",
    "with open(prompts_output_path, \"w\") as f:\n",
    "    json.dump(comprehensive_prompts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having think label (CoT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comprehensive_prompt(text):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive prompt with Chain of Thought (CoT) for multi-complication assessment.\n",
    "    \n",
    "    This function creates a \"comprehensive strategy\" prompt that requires the AI to evaluate all possible\n",
    "    post-operative complications simultaneously while providing explicit reasoning. The prompt\n",
    "    directly formats patient medical records and demands structured thinking before diagnosis.\n",
    "    \n",
    "    Key features of the comprehensive strategy prompt:\n",
    "    - Comprehensive evaluation of all 22 predefined complications at once\n",
    "    - Mandatory \"think\" field requiring step-by-step reasoning process\n",
    "    - Structured JSON output with both reasoning and diagnosis components\n",
    "    - Direct formatting of medical records into the prompt\n",
    "    \n",
    "    Args:\n",
    "        text (str): The full content of the prompt definition file (e.g., prompt.md),\n",
    "                    containing the definitions of post-operative complication categories\n",
    "                    and their grading rules.\n",
    "    \n",
    "    Returns:\n",
    "        str: A complete prompt string ready for use with medical record content appended.\n",
    "             The prompt includes instructions, complication definitions, output format,\n",
    "             and placeholders for patient data.\n",
    "    \"\"\"\n",
    "    # Define markers to identify and extract specific sections from the input text\n",
    "    complication_flag = \"## 术后并发症类别\"\n",
    "    grading_flag = \"## 常规分级\"\n",
    "    \n",
    "    # Extract the section detailing all complication categories and their definitions\n",
    "    complications = text[text.find(complication_flag) + len(complication_flag): text.find(grading_flag)]\n",
    "    \n",
    "    # Extract and format the general grading rules, replacing newlines with tabs for better formatting\n",
    "    grading = text[text.find(grading_flag) + len(grading_flag):].replace(\"\\n\", \"\\t\")\n",
    "    \n",
    "    # Define the initial instruction establishing the AI's role and comprehensive assessment task\n",
    "    instruction = '你是一名资深外科医生，你的任务是根据患者的资料，判断患者术后出现哪些并发症，并发症的诊断依据:\\n'                \n",
    "    \n",
    "    # Define the structured output format requiring both reasoning (think) and diagnosis (complications)\n",
    "    # This implements Chain of Thought methodology for improved diagnostic accuracy\n",
    "    output_structure = f\"\"\"\n",
    "### 输出json格式\n",
    "1. 首先，输出一个think字段，内容为一个数组，每个元素是一个字符串，表示对病例的思考和考虑过程。例如：\n",
    "    * \"患者术后恢复良好，无明显不适\"\n",
    "    * \"肌钙蛋白T升高，提示可能存在心肌损伤\"\n",
    "2. 然后，输出一个complications字段，内容为一个数组，每个元素包含：\n",
    "    * name: 并发症的名称，必须是22个预定义并发症之一\n",
    "    * grading: 严重程度分级，只能是以下四个选项之一：\n",
    "        * \"轻\" - 轻度：无需治疗\n",
    "        * \"中\" - 中度：需治疗，无长期影响\n",
    "        * \"重\" - 重度：导致器官功能受损或死亡，显著延长住院时间\n",
    "        * \"Null\" - 无分级\n",
    "\n",
    "完整格式示例：\n",
    "{{\n",
    "  \"think\": [\n",
    "    \"患者肾移植术后，根据指南排除急性肾损伤的诊断。\",\n",
    "    \"术后首次肌钙蛋白T升高至0.040 ng/mL，符合非心脏手术后心肌损伤的定义。\"\n",
    "  ],\n",
    "  \"complications\": [\n",
    "    {{\n",
    "      \"name\": \"非心脏手术后心肌损伤\",\n",
    "      \"grading\": \"Null\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "注意：\n",
    "- 如果没有发现术后并发症，请在complications数组中写明\"无术后并发症\"。\n",
    "- 如发现了术后并发症，则必须包含在上述的22个之中，禁止输出自定义的并发症\n",
    "- 常规分级按照{grading}\n",
    "### 病历资料\n",
    "\"\"\"\n",
    "    # Concatenate the instruction, extracted complication categories, and output structure\n",
    "    # to form the complete prompt string ready for medical record content\n",
    "    return instruction + complications + output_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "import json\n",
    "prompts_output_path = \"comprehensive_prompts.json\"\n",
    "\n",
    "with open(\"defination.md\", \"r\") as f:\n",
    "    text = f.read()\n",
    "comprehensive_prompts = {}\n",
    "with open(\"../data_source/medical_record_example.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for id, medical_record in data.items():\n",
    "    comprehensive_prompts[id] = get_comprehensive_prompt(text) + medical_record\n",
    "with open(prompts_output_path, \"w\") as f:\n",
    "    json.dump(comprehensive_prompts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified prompts\n",
    "\n",
    "After analyzing model errors, we improved prompts with four key changes:\n",
    "\n",
    "1. **Enhanced Diagnostic Specificity** - Added exclusion criteria (e.g., no acute kidney injury after kidney transplant)\n",
    "2. **Documentation Clarification** - Handled incomplete records (e.g., paralytic ileus needs GI symptoms)  \n",
    "3. **Differential Diagnostic Refinement** - Reduced false positives (e.g., distinguish postop bleeding from intraop blood loss)\n",
    "4. **Anatomical Precision Enhancement** - Expanded definitions (e.g., anastomotic leakage includes external leakage and imaging findings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存hard_prompts 为json\n",
    "import json\n",
    "prompts_output_path = \"comprehensive_prompts_modified.json\"\n",
    "\n",
    "with open(\"defination_modified.md\", \"r\") as f:\n",
    "    text = f.read()\n",
    "comprehensive_prompts = {}\n",
    "with open(\"../data_source/medical_record_example.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for id, medical_record in data.items():\n",
    "    comprehensive_prompts[id] = get_comprehensive_prompt(text) + medical_record\n",
    "with open(prompts_output_path, \"w\") as f:\n",
    "    json.dump(comprehensive_prompts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted strategy\n",
    "\n",
    "Instead of evaluating all 22 complications at once, this strategy focuses on one complication per call:\n",
    "\n",
    "- Reduces cognitive load for smaller models\n",
    "- Each prompt: single complication → True/False + severity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_targeted_prompt(text):\n",
    "    \"\"\"\n",
    "    Generates targeted prompts for single-complication assessment (targeted strategy).\n",
    "    \n",
    "    Args:\n",
    "        text (str): Content from prompt definition file (e.g., prompt_promote.md)\n",
    "                   containing complication categories and grading rules\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary mapping complication names to their specific prompts\n",
    "    \"\"\"\n",
    "    # Extract complication categories and grading rules from input text\n",
    "    complication_flag = \"## 术后并发症类别\"\n",
    "    grading_flag = \"## 常规分级\"\n",
    "    complications = text[text.find(complication_flag) + len(complication_flag): text.find(grading_flag)]\n",
    "    complication_list = re.split(r'\\d+\\.\\s', complications)[1:]\n",
    "    grading = text[text.find(grading_flag) + len(grading_flag):].replace(\"\\n\", \"\\t\")\n",
    "    \n",
    "    # Define instruction template for single-complication assessment\n",
    "    instruction = '''你是一名资深外科医生，你的任务是根据病例资料，判断患者术后是否出现{complication}，该并发症的诊断依据:\\n'''\n",
    "    \n",
    "    # Define streamlined output structure for targeted evaluation\n",
    "    output_structure = \"\"\"\n",
    "注意诊断标准必须全部符合（除非标准明确指出符合其中之一）。请输出如下json格式：\n",
    "{{\"think\": \"...(你的step by step思考过程)\", \"bool\": \"True/False(判断患者是否出现并发症，只能输出True和False的其中一个)\", \"grading\" \"Null/轻/中/重度（该并发症的严重程度，只能输出一种）\"}}\n",
    "病历资料：\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate individual prompts for each complication\n",
    "    targeted_complications = {}\n",
    "    for complication in complication_list:\n",
    "        complication_name, complication_std = complication.split(\"\\n\", 1)\n",
    "        _instruction = instruction.format(complication=complication_name, pt_info=\"{pt_info}\")\n",
    "        targeted_complications[complication_name] = _instruction + complication_std.replace(\"常规分级\", grading) + output_structure\n",
    "    \n",
    "    return targeted_complications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save targeted prompts as json\n",
    "import json\n",
    "with open(\"defination_modified.md\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "targeted_complications = get_targeted_prompt(text)\n",
    "\n",
    "with open(\"../data_source/medical_record_example.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "targeted_prompts = {}\n",
    "for id, medical_record in data.items():\n",
    "    targeted_prompts[id] = {key: value + medical_record for key, value in targeted_complications.items()}\n",
    "\n",
    "with open(\"targeted_prompts.json\", \"w\") as f:\n",
    "    json.dump(targeted_prompts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 100\n",
      "Validation set size: 46\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# Generate a list of numbers from 1 to 146\n",
    "all_ids = list(range(1, 147))\n",
    "\n",
    "# Shuffle the list of IDs randomly\n",
    "random.shuffle(all_ids)\n",
    "\n",
    "# Define the sizes for train and validation sets\n",
    "train_size = 100\n",
    "val_size = 46\n",
    "\n",
    "# Split the shuffled IDs into train and validation sets\n",
    "train_ids = all_ids[:train_size]\n",
    "val_ids = all_ids[train_size:train_size + val_size]\n",
    "\n",
    "# Create a dictionary representing the train/validation split\n",
    "split_data = {\n",
    "    \"train\": train_ids,\n",
    "    \"val\": val_ids\n",
    "}\n",
    "\n",
    "with open(\"../data_source/center1/train_val.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(split_data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
